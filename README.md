# LLM Music Generation Project

Ce projet impl√©mente un mod√®le de langage (LLM) bas√© sur l'architecture Transformer pour g√©n√©rer de la musique √† partir de fichiers MIDI.

## üöÄ Quick Start pour Collaborateurs

**Nouveau collaborateur ?** Consultez le guide complet : **[SETUP.md](SETUP.md)**

Le guide SETUP.md contient toutes les instructions d√©taill√©es pour :
- Cloner le projet
- T√©l√©charger le dataset GrandMidiPiano
- Pr√©parer les donn√©es
- Entra√Æner le mod√®le

## Pr√©requis

- **Dataset MIDI** : GrandMidiPiano ou tout autre dataset MIDI ([instructions dans SETUP.md](SETUP.md))
- **Python 3.8+**
- **15 GB d'espace disque**
- **GPU recommand√©** (optionnel mais acc√©l√®re l'entra√Ænement)

## Installation

```bash
pip install -r requirements.txt
```

## Structure du Projet

```
projet-midi/
‚îú‚îÄ‚îÄ config.py              # Configuration et hyperparam√®tres
‚îú‚îÄ‚îÄ midi2tokens.py         # Convertir MIDI ‚Üí Tokens
‚îú‚îÄ‚îÄ tokens2midi.py         # Convertir Tokens ‚Üí MIDI
‚îú‚îÄ‚îÄ data_preparation.py    # Pr√©paration des donn√©es et tokenization
‚îú‚îÄ‚îÄ model.py              # Architecture du mod√®le Transformer
‚îú‚îÄ‚îÄ train.py              # Script d'entra√Ænement
‚îú‚îÄ‚îÄ generate.py           # Script de g√©n√©ration de musique
‚îú‚îÄ‚îÄ requirements.txt      # D√©pendances
‚îî‚îÄ‚îÄ data/                 # Donn√©es (cr√©√© automatiquement)
    ‚îú‚îÄ‚îÄ tokenizer.pkl
    ‚îî‚îÄ‚îÄ training_data.pkl
```

## Utilisation

### 1. Convertir un fichier MIDI en tokens

```bash
python midi2tokens.py <fichier.mid> <output.txt>
```

Exemple:
```bash
python midi2tokens.py music.mid tokens.txt
```

### 2. Pr√©parer les donn√©es pour l'entra√Ænement

```bash
python data_preparation.py
```

Cela va :
- Analyser le fichier `exempleFichierToken.txt`
- Cr√©er le vocabulaire
- G√©n√©rer les s√©quences d'entra√Ænement
- Sauvegarder dans `data/`

### 3. Entra√Æner le mod√®le

```bash
python train.py
```

Le mod√®le sera entra√Æn√© pendant 50 epochs. Les checkpoints seront sauvegard√©s dans `models/`.

### 4. G√©n√©rer de la musique

```bash
python generate.py <length> [temperature] [top_k]
```

Exemple:
```bash
python generate.py 1000 0.8 50
```

Cela g√©n√®rera:
- `output/generated_tokens.txt` : Les tokens g√©n√©r√©s
- `output/generated_music.mid` : Le fichier MIDI jouable

### 5. Convertir des tokens en MIDI

```bash
python tokens2midi.py <tokens.txt> <output.mid> [tempo]
```

Exemple:
```bash
python tokens2midi.py tokens.txt music.mid 120
```

## Architecture du Mod√®le

Le mod√®le utilise l'architecture Transformer avec :

- **Embedding Layer** : Convertit les tokens en vecteurs
- **Positional Encoding** : Encodage sinuso√Ødal des positions
- **4 Transformer Blocks** avec :
  - Multi-head attention (4 t√™tes)
  - Feed-forward network
  - Layer normalization
  - Residual connections
- **Output Layer** : Pr√©dit le prochain token

### Hyperparam√®tres (config.py)

- S√©quence length : 256
- Embedding dim : 128
- Nombre de t√™tes : 4
- Nombre de couches : 4
- Batch size : 32
- Learning rate : 0.0001

## Format des Tokens

Chaque note est repr√©sent√©e par 3 tokens :

```
POSITION_<time>   # Position temporelle (en ticks)
NOTE_ON_<pitch>   # Hauteur de la note (0-127)
DURATION_<dur>    # Dur√©e de la note (en ticks)
```

Exemple:
```
POSITION_0
NOTE_ON_60
DURATION_480
```

## R√©sultats

Apr√®s l'entra√Ænement, vous trouverez :

- `models/best_model.pt` : Meilleur mod√®le
- `models/checkpoint_epoch_X.pt` : Checkpoints p√©riodiques
- `output/training_loss.png` : Graphique des pertes
- `output/generated_music.mid` : Musique g√©n√©r√©e

## Notes

- Le mod√®le est entra√Æn√© sur un seul instrument (piano)
- La qualit√© de g√©n√©ration d√©pend de la quantit√© et diversit√© des donn√©es
- Vous pouvez ajuster les hyperparam√®tres dans `config.py`

## Auteur

Projet r√©alis√© dans le cadre du cours sur les LLM pour la musique.
